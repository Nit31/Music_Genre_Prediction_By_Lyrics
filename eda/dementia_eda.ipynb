{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T08:16:59.405088Z",
     "start_time": "2024-04-11T08:16:57.451202Z"
    }
   },
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from torch.nn import functional as F\n",
    "sys.path.insert(0, '../src')\n",
    "from clean_text import text_preprocessing_pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "model_name = 'roberta-base'\n",
    "MAX_LEN = 200"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PCA on a summary vector from roberta",
   "id": "974ffd78e7b94f0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T21:34:49.812948Z",
     "start_time": "2024-04-10T21:34:48.444100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.getcwd() + '/../data/perfect_dataset.csv')\n",
    "df = df.sample(frac=0.1).reset_index(drop=True)\n",
    "# clean the text\n",
    "df['text'] = df['text'].apply(text_preprocessing_pipeline)\n",
    "# get distinct tags\n",
    "target_cols = df['tag'].unique()\n",
    "# one hot encode the tags\n",
    "encoder = OneHotEncoder()\n",
    "label = encoder.fit_transform(df[['tag']]).toarray()\n",
    "# append one hot encoded label to the dataframe with distinct tags as columns\n",
    "df = pd.concat([df, pd.DataFrame(label, columns=target_cols)], axis=1)\n",
    "# reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "id": "b9894ff5bda90680",
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/john/DataspellProjects/AnalyzingLyricsByAI/perfect_dataset.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msample(frac\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# clean the text\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\u001B[38;5;241m.\u001B[39mread(nrows)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mread(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m         nrows\n\u001B[1;32m   1925\u001B[0m     )\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread_low_memory(nrows)\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:905\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:874\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:891\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:2061\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T21:34:49.814244Z",
     "start_time": "2024-04-10T21:34:49.813945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(model_name)\n",
    "        # self.l2 = torch.nn.Dropout(0.3)\n",
    "        # self.l1 = torch.nn.Linear(768, 256)\n",
    "        self.fc = torch.nn.Linear(768,5)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, features = self.roberta(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        #features = F.relu(self.l1(features))\n",
    "        # output_2 = self.l2(output_1)\n",
    "        output = F.softmax(self.fc(features), dim=1)\n",
    "        return output\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = BERTClass()\n",
    "model.load_state_dict(torch.load(os.getcwd() + '/../model/model4.bin'))\n",
    "model.to(device)\n",
    "\n",
    "# from the model get only the features from the forward pass\n",
    "def get_features(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    _, features = model.roberta(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "    return features.cpu().detach().numpy()"
   ],
   "id": "30974cf8e95c2202",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T21:34:49.814832Z",
     "start_time": "2024-04-10T21:34:49.814767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['features'] = df['text'].apply(get_features)\n",
    "df.features = df.features.apply(lambda x: x.reshape(-1))\n",
    "pca = PCA(n_components=2)\n",
    "pca = pca.fit(df['features'].to_list())\n",
    "df['pca'] = df['features'].apply(lambda x: pca.transform([x])[0])\n",
    "df['pca_x'] = df['pca'].apply(lambda x: x[0])\n",
    "df['pca_y'] = df['pca'].apply(lambda x: x[1])"
   ],
   "id": "fc97e42886daad40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.scatterplot(x='pca_x', y='pca_y', hue='tag', data=df)\n",
    "plt.savefig('pca.png')"
   ],
   "id": "4dda0a2f5c1c2d1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Accuracy | Final dataset | Classical ML + roberta",
   "id": "666edf099d758f4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "roberta random sample test 7000 accuracy 0.7477142857142857\n",
    "\n",
    "tf-idf sgd 0.6252857142857143 \n",
    "\n",
    "tf-idf logreg 0.6317142857142857 \n",
    "\n",
    "tf-idf knn 0.2927142857142857\n",
    "\n",
    "tf-df random forest 0.614\n",
    "\n",
    "tf-idf grad boost 0.61"
   ],
   "id": "ca3fb2602bc8266c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mean f1 score for each model\n",
    "metrics = pd.read_csv('metrics.csv')\n",
    "metrics.head()"
   ],
   "id": "bce309a03109ba82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = metrics.rename(columns={'Unnamed: 0': 'model'})\n",
    "metrics_melted = pd.melt(metrics, id_vars=['model'], var_name='metric', value_name='value')\n",
    "metrics_melted = metrics_melted.sort_values(by='value', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='metric', y='value', hue='model', data=metrics_melted, dodge=False)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "id": "395ef262ce45616f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
